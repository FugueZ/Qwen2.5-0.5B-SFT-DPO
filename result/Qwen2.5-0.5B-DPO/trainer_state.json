{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9987931450639636,
  "eval_steps": 100,
  "global_step": 6213,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.048274197441467534,
      "grad_norm": 20.62273597717285,
      "learning_rate": 9.839047159182359e-07,
      "logits/chosen": -2.0975353717803955,
      "logits/rejected": -2.0598268508911133,
      "logps/chosen": -397.0216369628906,
      "logps/rejected": -352.5683898925781,
      "loss": 0.6923,
      "rewards/accuracies": 0.5766667127609253,
      "rewards/chosen": 0.0027786337304860353,
      "rewards/margins": 0.0016119510401040316,
      "rewards/rejected": 0.0011666828067973256,
      "step": 100
    },
    {
      "epoch": 0.048274197441467534,
      "eval_logits/chosen": -2.0078563690185547,
      "eval_logits/rejected": -2.042914628982544,
      "eval_logps/chosen": -393.86163330078125,
      "eval_logps/rejected": -349.5065612792969,
      "eval_loss": 0.6911276578903198,
      "eval_rewards/accuracies": 0.6397205591201782,
      "eval_rewards/chosen": 0.006008849944919348,
      "eval_rewards/margins": 0.00409031892195344,
      "eval_rewards/rejected": 0.0019185307901352644,
      "eval_runtime": 294.3508,
      "eval_samples_per_second": 3.397,
      "eval_steps_per_second": 1.135,
      "step": 100
    },
    {
      "epoch": 0.09654839488293507,
      "grad_norm": 21.755699157714844,
      "learning_rate": 9.678094318364718e-07,
      "logits/chosen": NaN,
      "logits/rejected": -1.9941587448120117,
      "logps/chosen": -363.457275390625,
      "logps/rejected": -324.1372375488281,
      "loss": 0.689,
      "rewards/accuracies": 0.6116666793823242,
      "rewards/chosen": 0.007467212621122599,
      "rewards/margins": 0.008527607657015324,
      "rewards/rejected": -0.0010603960836306214,
      "step": 200
    },
    {
      "epoch": 0.09654839488293507,
      "eval_logits/chosen": -2.0045666694641113,
      "eval_logits/rejected": -2.038936138153076,
      "eval_logps/chosen": -393.8541259765625,
      "eval_logps/rejected": -349.5659484863281,
      "eval_loss": 0.6879495978355408,
      "eval_rewards/accuracies": 0.6257485151290894,
      "eval_rewards/chosen": 0.006759585812687874,
      "eval_rewards/margins": 0.010776160284876823,
      "eval_rewards/rejected": -0.00401657447218895,
      "eval_runtime": 294.2,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 200
    },
    {
      "epoch": 0.14482259232440262,
      "grad_norm": 22.76446533203125,
      "learning_rate": 9.517141477547078e-07,
      "logits/chosen": -2.1096909046173096,
      "logits/rejected": -2.0743935108184814,
      "logps/chosen": -389.6990966796875,
      "logps/rejected": -355.4548034667969,
      "loss": 0.6877,
      "rewards/accuracies": 0.5950000286102295,
      "rewards/chosen": 0.008472941815853119,
      "rewards/margins": 0.011300832964479923,
      "rewards/rejected": -0.002827893476933241,
      "step": 300
    },
    {
      "epoch": 0.14482259232440262,
      "eval_logits/chosen": -2.003838300704956,
      "eval_logits/rejected": -2.0379559993743896,
      "eval_logps/chosen": -393.76104736328125,
      "eval_logps/rejected": -349.5200500488281,
      "eval_loss": 0.6857457160949707,
      "eval_rewards/accuracies": 0.6307385563850403,
      "eval_rewards/chosen": 0.016069581732153893,
      "eval_rewards/margins": 0.015497020445764065,
      "eval_rewards/rejected": 0.0005725629744119942,
      "eval_runtime": 294.2924,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 300
    },
    {
      "epoch": 0.19309678976587014,
      "grad_norm": 16.966882705688477,
      "learning_rate": 9.356188636729438e-07,
      "logits/chosen": -2.0451953411102295,
      "logits/rejected": -1.9991487264633179,
      "logps/chosen": -397.5121765136719,
      "logps/rejected": -353.60101318359375,
      "loss": 0.6859,
      "rewards/accuracies": 0.6166667342185974,
      "rewards/chosen": 0.016258174553513527,
      "rewards/margins": 0.01555568352341652,
      "rewards/rejected": 0.000702490215189755,
      "step": 400
    },
    {
      "epoch": 0.19309678976587014,
      "eval_logits/chosen": -2.003610849380493,
      "eval_logits/rejected": -2.037660837173462,
      "eval_logps/chosen": -393.6936340332031,
      "eval_logps/rejected": -349.4954528808594,
      "eval_loss": 0.6837807893753052,
      "eval_rewards/accuracies": 0.6317365169525146,
      "eval_rewards/chosen": 0.02281205914914608,
      "eval_rewards/margins": 0.01978030800819397,
      "eval_rewards/rejected": 0.003031755331903696,
      "eval_runtime": 294.2809,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 400
    },
    {
      "epoch": 0.24137098720733768,
      "grad_norm": 17.630388259887695,
      "learning_rate": 9.195235795911798e-07,
      "logits/chosen": -2.0218265056610107,
      "logits/rejected": -1.9047738313674927,
      "logps/chosen": -367.9720458984375,
      "logps/rejected": -336.5405578613281,
      "loss": 0.68,
      "rewards/accuracies": 0.6500000953674316,
      "rewards/chosen": 0.026246750727295876,
      "rewards/margins": 0.02775459736585617,
      "rewards/rejected": -0.0015078444266691804,
      "step": 500
    },
    {
      "epoch": 0.24137098720733768,
      "eval_logits/chosen": -2.0048229694366455,
      "eval_logits/rejected": -2.0385324954986572,
      "eval_logps/chosen": -393.7021789550781,
      "eval_logps/rejected": -349.5723571777344,
      "eval_loss": 0.680801510810852,
      "eval_rewards/accuracies": 0.6367265582084656,
      "eval_rewards/chosen": 0.021950194612145424,
      "eval_rewards/margins": 0.026607180014252663,
      "eval_rewards/rejected": -0.004656984005123377,
      "eval_runtime": 294.4536,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 500
    },
    {
      "epoch": 0.28964518464880523,
      "grad_norm": 17.027769088745117,
      "learning_rate": 9.034282955094157e-07,
      "logits/chosen": -1.9957549571990967,
      "logits/rejected": -2.0283050537109375,
      "logps/chosen": -381.5366516113281,
      "logps/rejected": -330.0430908203125,
      "loss": 0.6767,
      "rewards/accuracies": 0.653333306312561,
      "rewards/chosen": 0.0209194328635931,
      "rewards/margins": 0.035912562161684036,
      "rewards/rejected": -0.014993126504123211,
      "step": 600
    },
    {
      "epoch": 0.28964518464880523,
      "eval_logits/chosen": -2.0026514530181885,
      "eval_logits/rejected": -2.0357625484466553,
      "eval_logps/chosen": -393.728759765625,
      "eval_logps/rejected": -349.67138671875,
      "eval_loss": 0.6778385043144226,
      "eval_rewards/accuracies": 0.6317365169525146,
      "eval_rewards/chosen": 0.01929912529885769,
      "eval_rewards/margins": 0.03385968878865242,
      "eval_rewards/rejected": -0.014560562558472157,
      "eval_runtime": 294.231,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 600
    },
    {
      "epoch": 0.3379193820902727,
      "grad_norm": 23.49491310119629,
      "learning_rate": 8.873330114276518e-07,
      "logits/chosen": -2.1046946048736572,
      "logits/rejected": -2.031635046005249,
      "logps/chosen": -408.5994873046875,
      "logps/rejected": -353.8550109863281,
      "loss": 0.6764,
      "rewards/accuracies": 0.6066667437553406,
      "rewards/chosen": 0.014650993049144745,
      "rewards/margins": 0.03764103725552559,
      "rewards/rejected": -0.022990040481090546,
      "step": 700
    },
    {
      "epoch": 0.3379193820902727,
      "eval_logits/chosen": -2.0051450729370117,
      "eval_logits/rejected": -2.0381860733032227,
      "eval_logps/chosen": -393.7352294921875,
      "eval_logps/rejected": -349.72991943359375,
      "eval_loss": 0.6757262349128723,
      "eval_rewards/accuracies": 0.6317365765571594,
      "eval_rewards/chosen": 0.01865019090473652,
      "eval_rewards/margins": 0.03906545788049698,
      "eval_rewards/rejected": -0.02041526697576046,
      "eval_runtime": 294.4799,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 700
    },
    {
      "epoch": 0.38619357953174027,
      "grad_norm": 23.255632400512695,
      "learning_rate": 8.712377273458877e-07,
      "logits/chosen": -2.0165393352508545,
      "logits/rejected": -2.033951759338379,
      "logps/chosen": -387.8948059082031,
      "logps/rejected": -337.4272155761719,
      "loss": 0.6745,
      "rewards/accuracies": 0.6233333349227905,
      "rewards/chosen": 0.01585065759718418,
      "rewards/margins": 0.04179577901959419,
      "rewards/rejected": -0.02594512142241001,
      "step": 800
    },
    {
      "epoch": 0.38619357953174027,
      "eval_logits/chosen": -2.0043206214904785,
      "eval_logits/rejected": -2.037045478820801,
      "eval_logps/chosen": -393.6943359375,
      "eval_logps/rejected": -349.7444763183594,
      "eval_loss": 0.6735901236534119,
      "eval_rewards/accuracies": 0.6307384967803955,
      "eval_rewards/chosen": 0.022742336615920067,
      "eval_rewards/margins": 0.04461362585425377,
      "eval_rewards/rejected": -0.021871289238333702,
      "eval_runtime": 294.2257,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 800
    },
    {
      "epoch": 0.4344677769732078,
      "grad_norm": 17.09229850769043,
      "learning_rate": 8.551424432641235e-07,
      "logits/chosen": -2.007936477661133,
      "logits/rejected": -1.9986774921417236,
      "logps/chosen": -373.1879577636719,
      "logps/rejected": -346.5184631347656,
      "loss": 0.6763,
      "rewards/accuracies": 0.6166666746139526,
      "rewards/chosen": 0.01619783602654934,
      "rewards/margins": 0.03985003009438515,
      "rewards/rejected": -0.023652195930480957,
      "step": 900
    },
    {
      "epoch": 0.4344677769732078,
      "eval_logits/chosen": -2.0035336017608643,
      "eval_logits/rejected": -2.035997152328491,
      "eval_logps/chosen": -393.6900634765625,
      "eval_logps/rejected": -349.7850036621094,
      "eval_loss": 0.6719503402709961,
      "eval_rewards/accuracies": 0.6317365169525146,
      "eval_rewards/chosen": 0.023161662742495537,
      "eval_rewards/margins": 0.049085769802331924,
      "eval_rewards/rejected": -0.025924110785126686,
      "eval_runtime": 294.267,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 900
    },
    {
      "epoch": 0.48274197441467537,
      "grad_norm": 18.39153289794922,
      "learning_rate": 8.390471591823595e-07,
      "logits/chosen": -2.0370407104492188,
      "logits/rejected": -2.0686488151550293,
      "logps/chosen": -391.8982849121094,
      "logps/rejected": -347.3149108886719,
      "loss": 0.66,
      "rewards/accuracies": 0.6800000667572021,
      "rewards/chosen": 0.02631254494190216,
      "rewards/margins": 0.07555732131004333,
      "rewards/rejected": -0.04924476519227028,
      "step": 1000
    },
    {
      "epoch": 0.48274197441467537,
      "eval_logits/chosen": -2.0024008750915527,
      "eval_logits/rejected": -2.0342729091644287,
      "eval_logps/chosen": -393.7928161621094,
      "eval_logps/rejected": -349.9642639160156,
      "eval_loss": 0.6694495677947998,
      "eval_rewards/accuracies": 0.6267464756965637,
      "eval_rewards/chosen": 0.01289411261677742,
      "eval_rewards/margins": 0.05674286186695099,
      "eval_rewards/rejected": -0.04384875297546387,
      "eval_runtime": 294.2856,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 1000
    },
    {
      "epoch": 0.5310161718561429,
      "grad_norm": 20.323848724365234,
      "learning_rate": 8.229518751005955e-07,
      "logits/chosen": -2.041928291320801,
      "logits/rejected": -1.9901068210601807,
      "logps/chosen": -378.0498352050781,
      "logps/rejected": -342.6181335449219,
      "loss": 0.675,
      "rewards/accuracies": 0.596666693687439,
      "rewards/chosen": 0.0021838750690221786,
      "rewards/margins": 0.0465477891266346,
      "rewards/rejected": -0.04436391219496727,
      "step": 1100
    },
    {
      "epoch": 0.5310161718561429,
      "eval_logits/chosen": -2.002485513687134,
      "eval_logits/rejected": -2.0342161655426025,
      "eval_logps/chosen": -393.82208251953125,
      "eval_logps/rejected": -350.02978515625,
      "eval_loss": 0.6681901812553406,
      "eval_rewards/accuracies": 0.628742516040802,
      "eval_rewards/chosen": 0.009962476789951324,
      "eval_rewards/margins": 0.06036381050944328,
      "eval_rewards/rejected": -0.05040133371949196,
      "eval_runtime": 294.4659,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 1100
    },
    {
      "epoch": 0.5792903692976105,
      "grad_norm": 22.667804718017578,
      "learning_rate": 8.068565910188314e-07,
      "logits/chosen": -1.988657832145691,
      "logits/rejected": -2.0456349849700928,
      "logps/chosen": -377.07049560546875,
      "logps/rejected": -337.3842468261719,
      "loss": 0.6641,
      "rewards/accuracies": 0.6466666460037231,
      "rewards/chosen": 1.6817450159578584e-05,
      "rewards/margins": 0.07038702070713043,
      "rewards/rejected": -0.07037019729614258,
      "step": 1200
    },
    {
      "epoch": 0.5792903692976105,
      "eval_logits/chosen": -2.0026566982269287,
      "eval_logits/rejected": -2.0341291427612305,
      "eval_logps/chosen": -393.8265686035156,
      "eval_logps/rejected": -350.081787109375,
      "eval_loss": 0.6666975021362305,
      "eval_rewards/accuracies": 0.6267465353012085,
      "eval_rewards/chosen": 0.00951419398188591,
      "eval_rewards/margins": 0.06511621177196503,
      "eval_rewards/rejected": -0.05560201033949852,
      "eval_runtime": 294.1783,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 1200
    },
    {
      "epoch": 0.627564566739078,
      "grad_norm": 19.991531372070312,
      "learning_rate": 7.907613069370674e-07,
      "logits/chosen": -2.012756824493408,
      "logits/rejected": -1.9728924036026,
      "logps/chosen": -403.69012451171875,
      "logps/rejected": -350.6069641113281,
      "loss": 0.6637,
      "rewards/accuracies": 0.6549999713897705,
      "rewards/chosen": 0.003035576082766056,
      "rewards/margins": 0.07330528646707535,
      "rewards/rejected": -0.07026971131563187,
      "step": 1300
    },
    {
      "epoch": 0.627564566739078,
      "eval_logits/chosen": -2.0014195442199707,
      "eval_logits/rejected": -2.032646656036377,
      "eval_logps/chosen": -393.80511474609375,
      "eval_logps/rejected": -350.1076965332031,
      "eval_loss": 0.665151834487915,
      "eval_rewards/accuracies": 0.6287424564361572,
      "eval_rewards/chosen": 0.011664238758385181,
      "eval_rewards/margins": 0.06985467672348022,
      "eval_rewards/rejected": -0.058190442621707916,
      "eval_runtime": 294.3873,
      "eval_samples_per_second": 3.397,
      "eval_steps_per_second": 1.135,
      "step": 1300
    },
    {
      "epoch": 0.6758387641805454,
      "grad_norm": 21.66501235961914,
      "learning_rate": 7.746660228553033e-07,
      "logits/chosen": -2.048001766204834,
      "logits/rejected": NaN,
      "logps/chosen": -374.892578125,
      "logps/rejected": -326.3900451660156,
      "loss": 0.6656,
      "rewards/accuracies": 0.643333375453949,
      "rewards/chosen": 0.009334215894341469,
      "rewards/margins": 0.07080087810754776,
      "rewards/rejected": -0.06146666035056114,
      "step": 1400
    },
    {
      "epoch": 0.6758387641805454,
      "eval_logits/chosen": -2.0032615661621094,
      "eval_logits/rejected": -2.0345377922058105,
      "eval_logps/chosen": -393.6353759765625,
      "eval_logps/rejected": -349.9789733886719,
      "eval_loss": 0.6638193726539612,
      "eval_rewards/accuracies": 0.6317365765571594,
      "eval_rewards/chosen": 0.028632620349526405,
      "eval_rewards/margins": 0.07395278662443161,
      "eval_rewards/rejected": -0.04532016068696976,
      "eval_runtime": 294.2764,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 1400
    },
    {
      "epoch": 0.724112961622013,
      "grad_norm": 17.754728317260742,
      "learning_rate": 7.585707387735393e-07,
      "logits/chosen": -2.0701422691345215,
      "logits/rejected": -2.0278847217559814,
      "logps/chosen": -398.8599853515625,
      "logps/rejected": -334.4789123535156,
      "loss": 0.6665,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.027410317212343216,
      "rewards/margins": 0.0683891698718071,
      "rewards/rejected": -0.04097886011004448,
      "step": 1500
    },
    {
      "epoch": 0.724112961622013,
      "eval_logits/chosen": -2.002887010574341,
      "eval_logits/rejected": -2.034144401550293,
      "eval_logps/chosen": -393.61517333984375,
      "eval_logps/rejected": -349.99072265625,
      "eval_loss": 0.6627117991447449,
      "eval_rewards/accuracies": 0.6297404766082764,
      "eval_rewards/chosen": 0.030651766806840897,
      "eval_rewards/margins": 0.07715040445327759,
      "eval_rewards/rejected": -0.04649864882230759,
      "eval_runtime": 294.4546,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 1500
    },
    {
      "epoch": 0.7723871590634805,
      "grad_norm": 18.569026947021484,
      "learning_rate": 7.424754546917753e-07,
      "logits/chosen": -1.9790796041488647,
      "logits/rejected": -1.9785236120224,
      "logps/chosen": -382.47796630859375,
      "logps/rejected": -331.923583984375,
      "loss": 0.6617,
      "rewards/accuracies": 0.6399999856948853,
      "rewards/chosen": 0.02528546005487442,
      "rewards/margins": 0.07902348786592484,
      "rewards/rejected": -0.05373802036046982,
      "step": 1600
    },
    {
      "epoch": 0.7723871590634805,
      "eval_logits/chosen": -2.00192928314209,
      "eval_logits/rejected": -2.032991886138916,
      "eval_logps/chosen": -393.5255432128906,
      "eval_logps/rejected": -349.9413757324219,
      "eval_loss": 0.6614480018615723,
      "eval_rewards/accuracies": 0.628742516040802,
      "eval_rewards/chosen": 0.03962036967277527,
      "eval_rewards/margins": 0.08117815852165222,
      "eval_rewards/rejected": -0.04155778884887695,
      "eval_runtime": 294.4701,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 1600
    },
    {
      "epoch": 0.8206613565049481,
      "grad_norm": 23.323335647583008,
      "learning_rate": 7.263801706100112e-07,
      "logits/chosen": -2.040651798248291,
      "logits/rejected": -2.0047731399536133,
      "logps/chosen": -392.50164794921875,
      "logps/rejected": -343.9327392578125,
      "loss": 0.6626,
      "rewards/accuracies": 0.6466667056083679,
      "rewards/chosen": 0.037110257893800735,
      "rewards/margins": 0.07770273834466934,
      "rewards/rejected": -0.04059248045086861,
      "step": 1700
    },
    {
      "epoch": 0.8206613565049481,
      "eval_logits/chosen": -2.0025296211242676,
      "eval_logits/rejected": -2.033550262451172,
      "eval_logps/chosen": -393.52227783203125,
      "eval_logps/rejected": -349.972900390625,
      "eval_loss": 0.6603522896766663,
      "eval_rewards/accuracies": 0.6307384967803955,
      "eval_rewards/chosen": 0.03995068743824959,
      "eval_rewards/margins": 0.08466499298810959,
      "eval_rewards/rejected": -0.044714298099279404,
      "eval_runtime": 294.3158,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 1700
    },
    {
      "epoch": 0.8689355539464156,
      "grad_norm": 19.83936882019043,
      "learning_rate": 7.102848865282471e-07,
      "logits/chosen": -2.0081424713134766,
      "logits/rejected": -2.0141892433166504,
      "logps/chosen": -376.5226135253906,
      "logps/rejected": -341.99163818359375,
      "loss": 0.6615,
      "rewards/accuracies": 0.6050000190734863,
      "rewards/chosen": 0.03130120411515236,
      "rewards/margins": 0.08204706013202667,
      "rewards/rejected": -0.05074586346745491,
      "step": 1800
    },
    {
      "epoch": 0.8689355539464156,
      "eval_logits/chosen": -2.001396417617798,
      "eval_logits/rejected": -2.032139301300049,
      "eval_logps/chosen": -393.578369140625,
      "eval_logps/rejected": -350.0728759765625,
      "eval_loss": 0.659212589263916,
      "eval_rewards/accuracies": 0.6277444958686829,
      "eval_rewards/chosen": 0.03433546423912048,
      "eval_rewards/margins": 0.0890451967716217,
      "eval_rewards/rejected": -0.05470973625779152,
      "eval_runtime": 294.1962,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 1800
    },
    {
      "epoch": 0.9172097513878832,
      "grad_norm": 16.296274185180664,
      "learning_rate": 6.941896024464832e-07,
      "logits/chosen": -2.010507583618164,
      "logits/rejected": -1.9946545362472534,
      "logps/chosen": -357.58343505859375,
      "logps/rejected": -318.7701110839844,
      "loss": 0.6561,
      "rewards/accuracies": 0.6416666507720947,
      "rewards/chosen": 0.034996770322322845,
      "rewards/margins": 0.09516660869121552,
      "rewards/rejected": -0.06016983836889267,
      "step": 1900
    },
    {
      "epoch": 0.9172097513878832,
      "eval_logits/chosen": -2.001466751098633,
      "eval_logits/rejected": -2.03204083442688,
      "eval_logps/chosen": -393.6921691894531,
      "eval_logps/rejected": -350.2262878417969,
      "eval_loss": 0.6581841707229614,
      "eval_rewards/accuracies": 0.6297405362129211,
      "eval_rewards/chosen": 0.02295648492872715,
      "eval_rewards/margins": 0.093006432056427,
      "eval_rewards/rejected": -0.0700499564409256,
      "eval_runtime": 294.1305,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 1900
    },
    {
      "epoch": 0.9654839488293507,
      "grad_norm": 22.460208892822266,
      "learning_rate": 6.780943183647191e-07,
      "logits/chosen": -2.0454790592193604,
      "logits/rejected": -2.034745454788208,
      "logps/chosen": -383.0072326660156,
      "logps/rejected": -339.17169189453125,
      "loss": 0.6552,
      "rewards/accuracies": 0.6466667056083679,
      "rewards/chosen": 0.018002862110733986,
      "rewards/margins": 0.09804710745811462,
      "rewards/rejected": -0.08004424721002579,
      "step": 2000
    },
    {
      "epoch": 0.9654839488293507,
      "eval_logits/chosen": -2.00058650970459,
      "eval_logits/rejected": -2.0309438705444336,
      "eval_logps/chosen": -393.6890869140625,
      "eval_logps/rejected": -350.2687072753906,
      "eval_loss": 0.6570483446121216,
      "eval_rewards/accuracies": 0.6267464756965637,
      "eval_rewards/chosen": 0.0232606902718544,
      "eval_rewards/margins": 0.09755462408065796,
      "eval_rewards/rejected": -0.07429392635822296,
      "eval_runtime": 293.9915,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 2000
    },
    {
      "epoch": 1.013516775283611,
      "grad_norm": 20.53003692626953,
      "learning_rate": 6.619990342829551e-07,
      "logits/chosen": -2.053309202194214,
      "logits/rejected": -1.978857398033142,
      "logps/chosen": -416.616455078125,
      "logps/rejected": -352.92108154296875,
      "loss": 0.6433,
      "rewards/accuracies": 0.6582914590835571,
      "rewards/chosen": 0.02562551014125347,
      "rewards/margins": 0.12239164859056473,
      "rewards/rejected": -0.0967661440372467,
      "step": 2100
    },
    {
      "epoch": 1.013516775283611,
      "eval_logits/chosen": -1.9999282360076904,
      "eval_logits/rejected": -2.030078649520874,
      "eval_logps/chosen": -393.5963134765625,
      "eval_logps/rejected": -350.22454833984375,
      "eval_loss": 0.6559072136878967,
      "eval_rewards/accuracies": 0.6267464756965637,
      "eval_rewards/chosen": 0.03254407271742821,
      "eval_rewards/margins": 0.10242067277431488,
      "eval_rewards/rejected": -0.06987659633159637,
      "eval_runtime": 294.0291,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 2100
    },
    {
      "epoch": 1.0617909727250785,
      "grad_norm": 17.11591339111328,
      "learning_rate": 6.459037502011911e-07,
      "logits/chosen": -2.051514148712158,
      "logits/rejected": -2.0165512561798096,
      "logps/chosen": -410.82379150390625,
      "logps/rejected": -366.6446533203125,
      "loss": 0.6462,
      "rewards/accuracies": 0.6550000905990601,
      "rewards/chosen": 0.04701978713274002,
      "rewards/margins": 0.12431131303310394,
      "rewards/rejected": -0.07729154080152512,
      "step": 2200
    },
    {
      "epoch": 1.0617909727250785,
      "eval_logits/chosen": -1.999674916267395,
      "eval_logits/rejected": -2.029710292816162,
      "eval_logps/chosen": -393.63037109375,
      "eval_logps/rejected": -350.29833984375,
      "eval_loss": 0.6549903154373169,
      "eval_rewards/accuracies": 0.6277444958686829,
      "eval_rewards/chosen": 0.02913639508187771,
      "eval_rewards/margins": 0.10639211535453796,
      "eval_rewards/rejected": -0.07725570350885391,
      "eval_runtime": 294.1925,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 2200
    },
    {
      "epoch": 1.110065170166546,
      "grad_norm": 21.96933937072754,
      "learning_rate": 6.29808466119427e-07,
      "logits/chosen": -2.0760228633880615,
      "logits/rejected": -1.9977684020996094,
      "logps/chosen": -396.9475402832031,
      "logps/rejected": -358.72711181640625,
      "loss": 0.6576,
      "rewards/accuracies": 0.6150000095367432,
      "rewards/chosen": 0.02457878179848194,
      "rewards/margins": 0.10237960517406464,
      "rewards/rejected": -0.07780083268880844,
      "step": 2300
    },
    {
      "epoch": 1.110065170166546,
      "eval_logits/chosen": -1.9990415573120117,
      "eval_logits/rejected": -2.02908992767334,
      "eval_logps/chosen": -393.55908203125,
      "eval_logps/rejected": -350.24884033203125,
      "eval_loss": 0.6542119979858398,
      "eval_rewards/accuracies": 0.6297404766082764,
      "eval_rewards/chosen": 0.03626391664147377,
      "eval_rewards/margins": 0.10856861621141434,
      "eval_rewards/rejected": -0.07230468839406967,
      "eval_runtime": 294.1842,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 2300
    },
    {
      "epoch": 1.1583393676080136,
      "grad_norm": 19.944355010986328,
      "learning_rate": 6.13713182037663e-07,
      "logits/chosen": -2.0035009384155273,
      "logits/rejected": -2.0763962268829346,
      "logps/chosen": -380.396484375,
      "logps/rejected": -338.0153503417969,
      "loss": 0.6533,
      "rewards/accuracies": 0.6533333659172058,
      "rewards/chosen": 0.02108326181769371,
      "rewards/margins": 0.11018510162830353,
      "rewards/rejected": -0.08910183608531952,
      "step": 2400
    },
    {
      "epoch": 1.1583393676080136,
      "eval_logits/chosen": -1.9975407123565674,
      "eval_logits/rejected": -2.0274035930633545,
      "eval_logps/chosen": -393.6182556152344,
      "eval_logps/rejected": -350.3352355957031,
      "eval_loss": 0.6535907983779907,
      "eval_rewards/accuracies": 0.6317365169525146,
      "eval_rewards/chosen": 0.03034849278628826,
      "eval_rewards/margins": 0.11129505187273026,
      "eval_rewards/rejected": -0.08094654232263565,
      "eval_runtime": 294.1106,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 2400
    },
    {
      "epoch": 1.2066135650494811,
      "grad_norm": 17.693607330322266,
      "learning_rate": 5.976178979558989e-07,
      "logits/chosen": NaN,
      "logits/rejected": -1.9657727479934692,
      "logps/chosen": -374.6813659667969,
      "logps/rejected": -338.9755554199219,
      "loss": 0.6464,
      "rewards/accuracies": 0.6716667413711548,
      "rewards/chosen": 0.03341710567474365,
      "rewards/margins": 0.12711812555789948,
      "rewards/rejected": -0.09370101988315582,
      "step": 2500
    },
    {
      "epoch": 1.2066135650494811,
      "eval_logits/chosen": -1.997705340385437,
      "eval_logits/rejected": -2.0275521278381348,
      "eval_logps/chosen": -393.6078186035156,
      "eval_logps/rejected": -350.3561096191406,
      "eval_loss": 0.6528427600860596,
      "eval_rewards/accuracies": 0.6317364573478699,
      "eval_rewards/chosen": 0.031392212957143784,
      "eval_rewards/margins": 0.11442134529352188,
      "eval_rewards/rejected": -0.0830291211605072,
      "eval_runtime": 294.1129,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 2500
    },
    {
      "epoch": 1.2548877624909487,
      "grad_norm": 16.627843856811523,
      "learning_rate": 5.815226138741349e-07,
      "logits/chosen": -2.0165908336639404,
      "logits/rejected": -1.9530000686645508,
      "logps/chosen": -375.6187744140625,
      "logps/rejected": -333.9206237792969,
      "loss": 0.6441,
      "rewards/accuracies": 0.6483333706855774,
      "rewards/chosen": 0.03513501584529877,
      "rewards/margins": 0.13478682935237885,
      "rewards/rejected": -0.09965182095766068,
      "step": 2600
    },
    {
      "epoch": 1.2548877624909487,
      "eval_logits/chosen": -1.99915611743927,
      "eval_logits/rejected": -2.029001474380493,
      "eval_logps/chosen": -393.6357116699219,
      "eval_logps/rejected": -350.41448974609375,
      "eval_loss": 0.6520807147026062,
      "eval_rewards/accuracies": 0.6307385563850403,
      "eval_rewards/chosen": 0.02860105223953724,
      "eval_rewards/margins": 0.11747009307146072,
      "eval_rewards/rejected": -0.08886903524398804,
      "eval_runtime": 294.4233,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 2600
    },
    {
      "epoch": 1.303161959932416,
      "grad_norm": 19.82230567932129,
      "learning_rate": 5.654273297923709e-07,
      "logits/chosen": -2.021456003189087,
      "logits/rejected": -2.033740758895874,
      "logps/chosen": -378.8461608886719,
      "logps/rejected": -327.0732421875,
      "loss": 0.653,
      "rewards/accuracies": 0.643333375453949,
      "rewards/chosen": 0.01543677132576704,
      "rewards/margins": 0.11217188835144043,
      "rewards/rejected": -0.09673511236906052,
      "step": 2700
    },
    {
      "epoch": 1.303161959932416,
      "eval_logits/chosen": -1.9990313053131104,
      "eval_logits/rejected": -2.0287816524505615,
      "eval_logps/chosen": -393.56988525390625,
      "eval_logps/rejected": -350.3740539550781,
      "eval_loss": 0.6513715982437134,
      "eval_rewards/accuracies": 0.6337324976921082,
      "eval_rewards/chosen": 0.035180240869522095,
      "eval_rewards/margins": 0.12000701576471329,
      "eval_rewards/rejected": -0.08482678234577179,
      "eval_runtime": 294.0299,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 2700
    },
    {
      "epoch": 1.3514361573738838,
      "grad_norm": 21.730684280395508,
      "learning_rate": 5.493320457106067e-07,
      "logits/chosen": -2.0182700157165527,
      "logits/rejected": -1.9971832036972046,
      "logps/chosen": -384.15399169921875,
      "logps/rejected": -343.798828125,
      "loss": 0.6462,
      "rewards/accuracies": 0.6533333659172058,
      "rewards/chosen": 0.03922008350491524,
      "rewards/margins": 0.13233217597007751,
      "rewards/rejected": -0.09311210364103317,
      "step": 2800
    },
    {
      "epoch": 1.3514361573738838,
      "eval_logits/chosen": -1.9995734691619873,
      "eval_logits/rejected": -2.029405117034912,
      "eval_logps/chosen": -393.4353332519531,
      "eval_logps/rejected": -350.25714111328125,
      "eval_loss": 0.650755763053894,
      "eval_rewards/accuracies": 0.632734477519989,
      "eval_rewards/chosen": 0.04863861948251724,
      "eval_rewards/margins": 0.12177395075559616,
      "eval_rewards/rejected": -0.07313532382249832,
      "eval_runtime": 294.1703,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 2800
    },
    {
      "epoch": 1.399710354815351,
      "grad_norm": 23.14457893371582,
      "learning_rate": 5.332367616288426e-07,
      "logits/chosen": -2.0515995025634766,
      "logits/rejected": -1.9884135723114014,
      "logps/chosen": -393.7300720214844,
      "logps/rejected": -334.4898376464844,
      "loss": 0.6437,
      "rewards/accuracies": 0.6566666960716248,
      "rewards/chosen": 0.038086794316768646,
      "rewards/margins": 0.13737241923809052,
      "rewards/rejected": -0.09928560256958008,
      "step": 2900
    },
    {
      "epoch": 1.399710354815351,
      "eval_logits/chosen": -2.0011913776397705,
      "eval_logits/rejected": -2.0310218334198,
      "eval_logps/chosen": -393.470947265625,
      "eval_logps/rejected": -350.3282165527344,
      "eval_loss": 0.6501305103302002,
      "eval_rewards/accuracies": 0.6307384967803955,
      "eval_rewards/chosen": 0.045077987015247345,
      "eval_rewards/margins": 0.1253228783607483,
      "eval_rewards/rejected": -0.08024489879608154,
      "eval_runtime": 294.0702,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 2900
    },
    {
      "epoch": 1.4479845522568187,
      "grad_norm": 21.65049934387207,
      "learning_rate": 5.171414775470787e-07,
      "logits/chosen": -2.0216073989868164,
      "logits/rejected": -1.9695053100585938,
      "logps/chosen": -378.2334289550781,
      "logps/rejected": -330.03057861328125,
      "loss": 0.6427,
      "rewards/accuracies": 0.65666663646698,
      "rewards/chosen": 0.05157263204455376,
      "rewards/margins": 0.13662771880626678,
      "rewards/rejected": -0.08505509048700333,
      "step": 3000
    },
    {
      "epoch": 1.4479845522568187,
      "eval_logits/chosen": -2.0009636878967285,
      "eval_logits/rejected": -2.0307605266571045,
      "eval_logps/chosen": -393.4842834472656,
      "eval_logps/rejected": -350.3639221191406,
      "eval_loss": 0.649552583694458,
      "eval_rewards/accuracies": 0.6347305178642273,
      "eval_rewards/chosen": 0.04374665021896362,
      "eval_rewards/margins": 0.12756207585334778,
      "eval_rewards/rejected": -0.08381543308496475,
      "eval_runtime": 294.0177,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 3000
    },
    {
      "epoch": 1.4962587496982862,
      "grad_norm": 20.2060489654541,
      "learning_rate": 5.010461934653146e-07,
      "logits/chosen": -2.0579099655151367,
      "logits/rejected": -2.0059876441955566,
      "logps/chosen": -391.43426513671875,
      "logps/rejected": -353.4588928222656,
      "loss": 0.6489,
      "rewards/accuracies": 0.6216667294502258,
      "rewards/chosen": 0.04015164449810982,
      "rewards/margins": 0.13218696415424347,
      "rewards/rejected": -0.09203533083200455,
      "step": 3100
    },
    {
      "epoch": 1.4962587496982862,
      "eval_logits/chosen": -2.0013720989227295,
      "eval_logits/rejected": -2.03122615814209,
      "eval_logps/chosen": -393.4601745605469,
      "eval_logps/rejected": -350.3528747558594,
      "eval_loss": 0.649055004119873,
      "eval_rewards/accuracies": 0.6347305178642273,
      "eval_rewards/chosen": 0.04615628346800804,
      "eval_rewards/margins": 0.12886591255664825,
      "eval_rewards/rejected": -0.08270963281393051,
      "eval_runtime": 294.2032,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 3100
    },
    {
      "epoch": 1.5445329471397538,
      "grad_norm": 16.558300018310547,
      "learning_rate": 4.849509093835506e-07,
      "logits/chosen": -2.0554981231689453,
      "logits/rejected": -2.0345852375030518,
      "logps/chosen": -383.48895263671875,
      "logps/rejected": -327.470703125,
      "loss": 0.626,
      "rewards/accuracies": 0.7033332586288452,
      "rewards/chosen": 0.0660003274679184,
      "rewards/margins": 0.17774085700511932,
      "rewards/rejected": -0.11174052953720093,
      "step": 3200
    },
    {
      "epoch": 1.5445329471397538,
      "eval_logits/chosen": -1.999531865119934,
      "eval_logits/rejected": -2.0292415618896484,
      "eval_logps/chosen": -393.3612060546875,
      "eval_logps/rejected": -350.28271484375,
      "eval_loss": 0.6482909917831421,
      "eval_rewards/accuracies": 0.6337325572967529,
      "eval_rewards/chosen": 0.0560554563999176,
      "eval_rewards/margins": 0.13174942135810852,
      "eval_rewards/rejected": -0.07569396495819092,
      "eval_runtime": 294.2094,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 3200
    },
    {
      "epoch": 1.5928071445812213,
      "grad_norm": 28.821165084838867,
      "learning_rate": 4.6885562530178655e-07,
      "logits/chosen": -2.0499753952026367,
      "logits/rejected": -2.0360710620880127,
      "logps/chosen": -382.3279724121094,
      "logps/rejected": -328.9039306640625,
      "loss": 0.6521,
      "rewards/accuracies": 0.611666738986969,
      "rewards/chosen": 0.034509237855672836,
      "rewards/margins": 0.13101229071617126,
      "rewards/rejected": -0.09650306403636932,
      "step": 3300
    },
    {
      "epoch": 1.5928071445812213,
      "eval_logits/chosen": -1.9993821382522583,
      "eval_logits/rejected": -2.02911114692688,
      "eval_logps/chosen": -393.317138671875,
      "eval_logps/rejected": -350.2563171386719,
      "eval_loss": 0.6477939486503601,
      "eval_rewards/accuracies": 0.6347305178642273,
      "eval_rewards/chosen": 0.06045885011553764,
      "eval_rewards/margins": 0.13351169228553772,
      "eval_rewards/rejected": -0.07305284589529037,
      "eval_runtime": 294.3179,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 3300
    },
    {
      "epoch": 1.6410813420226888,
      "grad_norm": 16.14636993408203,
      "learning_rate": 4.527603412200225e-07,
      "logits/chosen": -2.044191598892212,
      "logits/rejected": -2.0238516330718994,
      "logps/chosen": -385.4246826171875,
      "logps/rejected": -343.0792541503906,
      "loss": 0.6531,
      "rewards/accuracies": 0.6050000190734863,
      "rewards/chosen": 0.044837821274995804,
      "rewards/margins": 0.12130481749773026,
      "rewards/rejected": -0.07646698504686356,
      "step": 3400
    },
    {
      "epoch": 1.6410813420226888,
      "eval_logits/chosen": -1.9997878074645996,
      "eval_logits/rejected": -2.0295915603637695,
      "eval_logps/chosen": -393.3128662109375,
      "eval_logps/rejected": -350.2598571777344,
      "eval_loss": 0.6473450660705566,
      "eval_rewards/accuracies": 0.6357285976409912,
      "eval_rewards/chosen": 0.06088678911328316,
      "eval_rewards/margins": 0.13429772853851318,
      "eval_rewards/rejected": -0.07341095060110092,
      "eval_runtime": 294.2161,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 3400
    },
    {
      "epoch": 1.6893555394641564,
      "grad_norm": 14.320995330810547,
      "learning_rate": 4.3666505713825846e-07,
      "logits/chosen": -1.9709653854370117,
      "logits/rejected": -1.9282357692718506,
      "logps/chosen": -403.1333923339844,
      "logps/rejected": -360.7632751464844,
      "loss": 0.6454,
      "rewards/accuracies": 0.6483333706855774,
      "rewards/chosen": 0.06060138717293739,
      "rewards/margins": 0.14417389035224915,
      "rewards/rejected": -0.08357251435518265,
      "step": 3500
    },
    {
      "epoch": 1.6893555394641564,
      "eval_logits/chosen": -1.9998918771743774,
      "eval_logits/rejected": -2.029654026031494,
      "eval_logps/chosen": -393.3072509765625,
      "eval_logps/rejected": -350.271240234375,
      "eval_loss": 0.6470354199409485,
      "eval_rewards/accuracies": 0.6317365169525146,
      "eval_rewards/chosen": 0.06144307181239128,
      "eval_rewards/margins": 0.13599100708961487,
      "eval_rewards/rejected": -0.07454793900251389,
      "eval_runtime": 294.3451,
      "eval_samples_per_second": 3.397,
      "eval_steps_per_second": 1.135,
      "step": 3500
    },
    {
      "epoch": 1.737629736905624,
      "grad_norm": 22.182758331298828,
      "learning_rate": 4.2056977305649443e-07,
      "logits/chosen": -1.9854694604873657,
      "logits/rejected": -2.024003744125366,
      "logps/chosen": -398.7853088378906,
      "logps/rejected": -339.7524108886719,
      "loss": 0.6442,
      "rewards/accuracies": 0.6516666412353516,
      "rewards/chosen": 0.06596392393112183,
      "rewards/margins": 0.14542987942695618,
      "rewards/rejected": -0.07946595549583435,
      "step": 3600
    },
    {
      "epoch": 1.737629736905624,
      "eval_logits/chosen": -1.9989770650863647,
      "eval_logits/rejected": -2.0286777019500732,
      "eval_logps/chosen": -393.2467346191406,
      "eval_logps/rejected": -350.226318359375,
      "eval_loss": 0.6466270089149475,
      "eval_rewards/accuracies": 0.6347305178642273,
      "eval_rewards/chosen": 0.06749708205461502,
      "eval_rewards/margins": 0.1375536024570465,
      "eval_rewards/rejected": -0.07005653530359268,
      "eval_runtime": 294.1223,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 3600
    },
    {
      "epoch": 1.7859039343470915,
      "grad_norm": 17.490713119506836,
      "learning_rate": 4.044744889747304e-07,
      "logits/chosen": -2.00557279586792,
      "logits/rejected": -1.9660453796386719,
      "logps/chosen": -379.9375,
      "logps/rejected": -354.751708984375,
      "loss": 0.6461,
      "rewards/accuracies": 0.6650000214576721,
      "rewards/chosen": 0.03981996700167656,
      "rewards/margins": 0.14581416547298431,
      "rewards/rejected": -0.10599420219659805,
      "step": 3700
    },
    {
      "epoch": 1.7859039343470915,
      "eval_logits/chosen": -1.9988009929656982,
      "eval_logits/rejected": -2.0283923149108887,
      "eval_logps/chosen": -393.29522705078125,
      "eval_logps/rejected": -350.2937927246094,
      "eval_loss": 0.6463308930397034,
      "eval_rewards/accuracies": 0.6337325572967529,
      "eval_rewards/chosen": 0.06264787167310715,
      "eval_rewards/margins": 0.13944371044635773,
      "eval_rewards/rejected": -0.07679583132266998,
      "eval_runtime": 294.0858,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 3700
    },
    {
      "epoch": 1.834178131788559,
      "grad_norm": 15.876031875610352,
      "learning_rate": 3.8837920489296634e-07,
      "logits/chosen": -1.9733163118362427,
      "logits/rejected": -1.9825897216796875,
      "logps/chosen": -360.00616455078125,
      "logps/rejected": -311.80975341796875,
      "loss": 0.6334,
      "rewards/accuracies": 0.6583333611488342,
      "rewards/chosen": 0.06078195571899414,
      "rewards/margins": 0.16542913019657135,
      "rewards/rejected": -0.1046471819281578,
      "step": 3800
    },
    {
      "epoch": 1.834178131788559,
      "eval_logits/chosen": -1.9989665746688843,
      "eval_logits/rejected": -2.028503179550171,
      "eval_logps/chosen": -393.240234375,
      "eval_logps/rejected": -350.26287841796875,
      "eval_loss": 0.6458693742752075,
      "eval_rewards/accuracies": 0.6347305178642273,
      "eval_rewards/chosen": 0.06815196573734283,
      "eval_rewards/margins": 0.1418602168560028,
      "eval_rewards/rejected": -0.07370826601982117,
      "eval_runtime": 294.214,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 3800
    },
    {
      "epoch": 1.8824523292300266,
      "grad_norm": 17.15043067932129,
      "learning_rate": 3.722839208112023e-07,
      "logits/chosen": -2.0761587619781494,
      "logits/rejected": -1.9501515626907349,
      "logps/chosen": -363.9217529296875,
      "logps/rejected": -345.3866271972656,
      "loss": 0.6386,
      "rewards/accuracies": 0.6700000166893005,
      "rewards/chosen": 0.08303406834602356,
      "rewards/margins": 0.15456494688987732,
      "rewards/rejected": -0.07153087854385376,
      "step": 3900
    },
    {
      "epoch": 1.8824523292300266,
      "eval_logits/chosen": -1.999597191810608,
      "eval_logits/rejected": -2.029233455657959,
      "eval_logps/chosen": -393.1950378417969,
      "eval_logps/rejected": -350.22772216796875,
      "eval_loss": 0.6454479694366455,
      "eval_rewards/accuracies": 0.6337325572967529,
      "eval_rewards/chosen": 0.07266603410243988,
      "eval_rewards/margins": 0.14286068081855774,
      "eval_rewards/rejected": -0.07019465416669846,
      "eval_runtime": 294.2577,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 3900
    },
    {
      "epoch": 1.9307265266714941,
      "grad_norm": 19.52524757385254,
      "learning_rate": 3.561886367294383e-07,
      "logits/chosen": -2.057873010635376,
      "logits/rejected": -2.0478880405426025,
      "logps/chosen": -366.1468505859375,
      "logps/rejected": -336.68292236328125,
      "loss": 0.6524,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.05741969123482704,
      "rewards/margins": 0.1283193826675415,
      "rewards/rejected": -0.07089970260858536,
      "step": 4000
    },
    {
      "epoch": 1.9307265266714941,
      "eval_logits/chosen": -2.000241756439209,
      "eval_logits/rejected": -2.029928207397461,
      "eval_logps/chosen": -393.2203063964844,
      "eval_logps/rejected": -350.2614440917969,
      "eval_loss": 0.6451821327209473,
      "eval_rewards/accuracies": 0.6337324976921082,
      "eval_rewards/chosen": 0.0701460912823677,
      "eval_rewards/margins": 0.14371255040168762,
      "eval_rewards/rejected": -0.07356646656990051,
      "eval_runtime": 294.1236,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 4000
    },
    {
      "epoch": 1.9790007241129617,
      "grad_norm": 19.575130462646484,
      "learning_rate": 3.4009335264767417e-07,
      "logits/chosen": -1.9843640327453613,
      "logits/rejected": -1.9648197889328003,
      "logps/chosen": -402.5364074707031,
      "logps/rejected": -343.6488342285156,
      "loss": 0.6344,
      "rewards/accuracies": 0.658333420753479,
      "rewards/chosen": 0.08237851411104202,
      "rewards/margins": 0.17159047722816467,
      "rewards/rejected": -0.08921197056770325,
      "step": 4100
    },
    {
      "epoch": 1.9790007241129617,
      "eval_logits/chosen": -1.9997602701187134,
      "eval_logits/rejected": -2.0293710231781006,
      "eval_logps/chosen": -393.1819763183594,
      "eval_logps/rejected": -350.2432861328125,
      "eval_loss": 0.6448333859443665,
      "eval_rewards/accuracies": 0.6317365169525146,
      "eval_rewards/chosen": 0.07397063076496124,
      "eval_rewards/margins": 0.14572162926197052,
      "eval_rewards/rejected": -0.07175099849700928,
      "eval_runtime": 294.0294,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 4100
    },
    {
      "epoch": 2.027033550567222,
      "grad_norm": 18.925539016723633,
      "learning_rate": 3.2399806856591015e-07,
      "logits/chosen": -2.024724245071411,
      "logits/rejected": -1.9882564544677734,
      "logps/chosen": -386.8633117675781,
      "logps/rejected": -334.0357971191406,
      "loss": 0.641,
      "rewards/accuracies": 0.644891083240509,
      "rewards/chosen": 0.051093585789203644,
      "rewards/margins": 0.1538342833518982,
      "rewards/rejected": -0.10274070501327515,
      "step": 4200
    },
    {
      "epoch": 2.027033550567222,
      "eval_logits/chosen": -2.000523567199707,
      "eval_logits/rejected": -2.0302236080169678,
      "eval_logps/chosen": -393.1715393066406,
      "eval_logps/rejected": -350.24224853515625,
      "eval_loss": 0.6445164084434509,
      "eval_rewards/accuracies": 0.6347305178642273,
      "eval_rewards/chosen": 0.07501904666423798,
      "eval_rewards/margins": 0.14666831493377686,
      "eval_rewards/rejected": -0.07164927572011948,
      "eval_runtime": 294.0101,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 4200
    },
    {
      "epoch": 2.0753077480086892,
      "grad_norm": 15.671224594116211,
      "learning_rate": 3.079027844841461e-07,
      "logits/chosen": -2.004328966140747,
      "logits/rejected": NaN,
      "logps/chosen": -368.8365478515625,
      "logps/rejected": -323.5030822753906,
      "loss": 0.6242,
      "rewards/accuracies": 0.6733334064483643,
      "rewards/chosen": 0.07396554946899414,
      "rewards/margins": 0.19757044315338135,
      "rewards/rejected": -0.1236049011349678,
      "step": 4300
    },
    {
      "epoch": 2.0753077480086892,
      "eval_logits/chosen": -2.000396966934204,
      "eval_logits/rejected": -2.030046224594116,
      "eval_logps/chosen": -393.18548583984375,
      "eval_logps/rejected": -350.27337646484375,
      "eval_loss": 0.6442180275917053,
      "eval_rewards/accuracies": 0.6337325572967529,
      "eval_rewards/chosen": 0.07362557202577591,
      "eval_rewards/margins": 0.14838865399360657,
      "eval_rewards/rejected": -0.07476306706666946,
      "eval_runtime": 294.0936,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 4300
    },
    {
      "epoch": 2.123581945450157,
      "grad_norm": 15.781147956848145,
      "learning_rate": 2.918075004023821e-07,
      "logits/chosen": -2.0528793334960938,
      "logits/rejected": -2.0677478313446045,
      "logps/chosen": -400.16632080078125,
      "logps/rejected": -334.6434020996094,
      "loss": 0.655,
      "rewards/accuracies": 0.6183333396911621,
      "rewards/chosen": 0.05636334791779518,
      "rewards/margins": 0.12906335294246674,
      "rewards/rejected": -0.07270002365112305,
      "step": 4400
    },
    {
      "epoch": 2.123581945450157,
      "eval_logits/chosen": -2.0006256103515625,
      "eval_logits/rejected": -2.0304009914398193,
      "eval_logps/chosen": -393.1365051269531,
      "eval_logps/rejected": -350.2242126464844,
      "eval_loss": 0.6439511775970459,
      "eval_rewards/accuracies": 0.6357285380363464,
      "eval_rewards/chosen": 0.07852279394865036,
      "eval_rewards/margins": 0.14836640655994415,
      "eval_rewards/rejected": -0.0698436051607132,
      "eval_runtime": 294.0027,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 4400
    },
    {
      "epoch": 2.1718561428916243,
      "grad_norm": 26.07447624206543,
      "learning_rate": 2.7571221632061803e-07,
      "logits/chosen": -2.0599308013916016,
      "logits/rejected": -2.0338735580444336,
      "logps/chosen": -383.5230407714844,
      "logps/rejected": -360.569091796875,
      "loss": 0.6344,
      "rewards/accuracies": 0.6683332920074463,
      "rewards/chosen": 0.05809388309717178,
      "rewards/margins": 0.16670776903629303,
      "rewards/rejected": -0.10861386358737946,
      "step": 4500
    },
    {
      "epoch": 2.1718561428916243,
      "eval_logits/chosen": -2.000877857208252,
      "eval_logits/rejected": -2.03057861328125,
      "eval_logps/chosen": -393.14886474609375,
      "eval_logps/rejected": -350.2550048828125,
      "eval_loss": 0.64373379945755,
      "eval_rewards/accuracies": 0.6337324976921082,
      "eval_rewards/chosen": 0.07728862762451172,
      "eval_rewards/margins": 0.1502077728509903,
      "eval_rewards/rejected": -0.07291913777589798,
      "eval_runtime": 294.3979,
      "eval_samples_per_second": 3.397,
      "eval_steps_per_second": 1.135,
      "step": 4500
    },
    {
      "epoch": 2.220130340333092,
      "grad_norm": 21.158933639526367,
      "learning_rate": 2.59616932238854e-07,
      "logits/chosen": -2.0527443885803223,
      "logits/rejected": -2.0468647480010986,
      "logps/chosen": -381.9109802246094,
      "logps/rejected": -348.6484680175781,
      "loss": 0.643,
      "rewards/accuracies": 0.6466666460037231,
      "rewards/chosen": 0.08780612796545029,
      "rewards/margins": 0.1542307734489441,
      "rewards/rejected": -0.06642463058233261,
      "step": 4600
    },
    {
      "epoch": 2.220130340333092,
      "eval_logits/chosen": -2.00178599357605,
      "eval_logits/rejected": -2.0315563678741455,
      "eval_logps/chosen": -393.1492004394531,
      "eval_logps/rejected": -350.26318359375,
      "eval_loss": 0.6434826850891113,
      "eval_rewards/accuracies": 0.6337324976921082,
      "eval_rewards/chosen": 0.0772513896226883,
      "eval_rewards/margins": 0.15099231898784637,
      "eval_rewards/rejected": -0.07374092191457748,
      "eval_runtime": 294.2417,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 4600
    },
    {
      "epoch": 2.2684045377745594,
      "grad_norm": 20.684846878051758,
      "learning_rate": 2.4352164815708993e-07,
      "logits/chosen": -2.0450963973999023,
      "logits/rejected": -2.033790111541748,
      "logps/chosen": -373.762451171875,
      "logps/rejected": -330.9046630859375,
      "loss": 0.6387,
      "rewards/accuracies": 0.6533333659172058,
      "rewards/chosen": 0.0659237802028656,
      "rewards/margins": 0.1583223193883896,
      "rewards/rejected": -0.09239856898784637,
      "step": 4700
    },
    {
      "epoch": 2.2684045377745594,
      "eval_logits/chosen": -2.00174880027771,
      "eval_logits/rejected": -2.0315306186676025,
      "eval_logps/chosen": -393.1008605957031,
      "eval_logps/rejected": -350.2220458984375,
      "eval_loss": 0.6432448625564575,
      "eval_rewards/accuracies": 0.6367264986038208,
      "eval_rewards/chosen": 0.0820854902267456,
      "eval_rewards/margins": 0.15171508491039276,
      "eval_rewards/rejected": -0.06962958723306656,
      "eval_runtime": 294.4689,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 4700
    },
    {
      "epoch": 2.316678735216027,
      "grad_norm": 18.880084991455078,
      "learning_rate": 2.274263640753259e-07,
      "logits/chosen": -2.018610715866089,
      "logits/rejected": -2.0072901248931885,
      "logps/chosen": -384.021728515625,
      "logps/rejected": -326.9579162597656,
      "loss": 0.6188,
      "rewards/accuracies": 0.6783333420753479,
      "rewards/chosen": 0.1196439266204834,
      "rewards/margins": 0.20949944853782654,
      "rewards/rejected": -0.08985554426908493,
      "step": 4800
    },
    {
      "epoch": 2.316678735216027,
      "eval_logits/chosen": -2.0009236335754395,
      "eval_logits/rejected": -2.0306012630462646,
      "eval_logps/chosen": -393.1003112792969,
      "eval_logps/rejected": -350.2365417480469,
      "eval_loss": 0.6430277824401855,
      "eval_rewards/accuracies": 0.6357285380363464,
      "eval_rewards/chosen": 0.08214117586612701,
      "eval_rewards/margins": 0.1532176285982132,
      "eval_rewards/rejected": -0.07107646763324738,
      "eval_runtime": 294.6045,
      "eval_samples_per_second": 3.394,
      "eval_steps_per_second": 1.134,
      "step": 4800
    },
    {
      "epoch": 2.3649529326574945,
      "grad_norm": 18.40664291381836,
      "learning_rate": 2.1133107999356186e-07,
      "logits/chosen": -2.02980899810791,
      "logits/rejected": -2.0111405849456787,
      "logps/chosen": -396.99578857421875,
      "logps/rejected": -362.6266784667969,
      "loss": 0.6234,
      "rewards/accuracies": 0.6866666674613953,
      "rewards/chosen": 0.09594564139842987,
      "rewards/margins": 0.19953453540802002,
      "rewards/rejected": -0.10358887910842896,
      "step": 4900
    },
    {
      "epoch": 2.3649529326574945,
      "eval_logits/chosen": -2.001168727874756,
      "eval_logits/rejected": -2.030829668045044,
      "eval_logps/chosen": -393.1175231933594,
      "eval_logps/rejected": -350.2648620605469,
      "eval_loss": 0.6428314447402954,
      "eval_rewards/accuracies": 0.6367264986038208,
      "eval_rewards/chosen": 0.08042453974485397,
      "eval_rewards/margins": 0.1543302685022354,
      "eval_rewards/rejected": -0.07390572130680084,
      "eval_runtime": 294.5978,
      "eval_samples_per_second": 3.394,
      "eval_steps_per_second": 1.134,
      "step": 4900
    },
    {
      "epoch": 2.4132271300989623,
      "grad_norm": 17.3960018157959,
      "learning_rate": 1.9523579591179784e-07,
      "logits/chosen": -2.0281755924224854,
      "logits/rejected": -2.0101492404937744,
      "logps/chosen": -402.6869812011719,
      "logps/rejected": -343.5242614746094,
      "loss": 0.6324,
      "rewards/accuracies": 0.6683333516120911,
      "rewards/chosen": 0.09015416353940964,
      "rewards/margins": 0.1718180775642395,
      "rewards/rejected": -0.08166392147541046,
      "step": 5000
    },
    {
      "epoch": 2.4132271300989623,
      "eval_logits/chosen": -2.001014471054077,
      "eval_logits/rejected": -2.030651092529297,
      "eval_logps/chosen": -393.0960388183594,
      "eval_logps/rejected": -350.2526550292969,
      "eval_loss": 0.6426399946212769,
      "eval_rewards/accuracies": 0.6367264986038208,
      "eval_rewards/chosen": 0.08256937563419342,
      "eval_rewards/margins": 0.15526127815246582,
      "eval_rewards/rejected": -0.0726918950676918,
      "eval_runtime": 294.7799,
      "eval_samples_per_second": 3.392,
      "eval_steps_per_second": 1.133,
      "step": 5000
    },
    {
      "epoch": 2.4615013275404296,
      "grad_norm": 21.01112174987793,
      "learning_rate": 1.791405118300338e-07,
      "logits/chosen": -2.0002946853637695,
      "logits/rejected": -1.9667048454284668,
      "logps/chosen": -369.3397521972656,
      "logps/rejected": -330.94354248046875,
      "loss": 0.6488,
      "rewards/accuracies": 0.6449999809265137,
      "rewards/chosen": 0.09169823676347733,
      "rewards/margins": 0.1453336626291275,
      "rewards/rejected": -0.053635429590940475,
      "step": 5100
    },
    {
      "epoch": 2.4615013275404296,
      "eval_logits/chosen": -2.0016725063323975,
      "eval_logits/rejected": -2.031398296356201,
      "eval_logps/chosen": -393.0589904785156,
      "eval_logps/rejected": -350.2156677246094,
      "eval_loss": 0.6424809098243713,
      "eval_rewards/accuracies": 0.6367264986038208,
      "eval_rewards/chosen": 0.08627082407474518,
      "eval_rewards/margins": 0.15526005625724792,
      "eval_rewards/rejected": -0.06898923218250275,
      "eval_runtime": 294.3108,
      "eval_samples_per_second": 3.398,
      "eval_steps_per_second": 1.135,
      "step": 5100
    },
    {
      "epoch": 2.5097755249818974,
      "grad_norm": 30.63504409790039,
      "learning_rate": 1.6304522774826977e-07,
      "logits/chosen": -2.026397228240967,
      "logits/rejected": -2.0157506465911865,
      "logps/chosen": -405.5210876464844,
      "logps/rejected": -328.4161376953125,
      "loss": 0.6331,
      "rewards/accuracies": 0.68666672706604,
      "rewards/chosen": 0.06964146345853806,
      "rewards/margins": 0.18055573105812073,
      "rewards/rejected": -0.11091426759958267,
      "step": 5200
    },
    {
      "epoch": 2.5097755249818974,
      "eval_logits/chosen": -2.0013632774353027,
      "eval_logits/rejected": -2.031078577041626,
      "eval_logps/chosen": -393.03985595703125,
      "eval_logps/rejected": -350.2024230957031,
      "eval_loss": 0.6423415541648865,
      "eval_rewards/accuracies": 0.6357284784317017,
      "eval_rewards/chosen": 0.08818814903497696,
      "eval_rewards/margins": 0.1558518260717392,
      "eval_rewards/rejected": -0.06766369193792343,
      "eval_runtime": 294.1065,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 5200
    },
    {
      "epoch": 2.5580497224233647,
      "grad_norm": 18.54377555847168,
      "learning_rate": 1.469499436665057e-07,
      "logits/chosen": -1.9802547693252563,
      "logits/rejected": -1.9432836771011353,
      "logps/chosen": -377.8954162597656,
      "logps/rejected": -340.758056640625,
      "loss": 0.6416,
      "rewards/accuracies": 0.6133333444595337,
      "rewards/chosen": 0.08404519408941269,
      "rewards/margins": 0.15532316267490387,
      "rewards/rejected": -0.07127796858549118,
      "step": 5300
    },
    {
      "epoch": 2.5580497224233647,
      "eval_logits/chosen": -2.0017240047454834,
      "eval_logits/rejected": -2.0315001010894775,
      "eval_logps/chosen": -393.03424072265625,
      "eval_logps/rejected": -350.19927978515625,
      "eval_loss": 0.6421900391578674,
      "eval_rewards/accuracies": 0.6377245187759399,
      "eval_rewards/chosen": 0.08875085413455963,
      "eval_rewards/margins": 0.15610067546367645,
      "eval_rewards/rejected": -0.06734981387853622,
      "eval_runtime": 294.1099,
      "eval_samples_per_second": 3.4,
      "eval_steps_per_second": 1.136,
      "step": 5300
    },
    {
      "epoch": 2.606323919864832,
      "grad_norm": 22.931873321533203,
      "learning_rate": 1.3085465958474167e-07,
      "logits/chosen": -2.064155101776123,
      "logits/rejected": -2.0444207191467285,
      "logps/chosen": -373.3894958496094,
      "logps/rejected": -339.8905334472656,
      "loss": 0.6445,
      "rewards/accuracies": 0.6616666913032532,
      "rewards/chosen": 0.07531659305095673,
      "rewards/margins": 0.15985532104969025,
      "rewards/rejected": -0.08453872799873352,
      "step": 5400
    },
    {
      "epoch": 2.606323919864832,
      "eval_logits/chosen": -2.001739978790283,
      "eval_logits/rejected": -2.031550168991089,
      "eval_logps/chosen": -393.01861572265625,
      "eval_logps/rejected": -350.1846923828125,
      "eval_loss": 0.642061173915863,
      "eval_rewards/accuracies": 0.6387225389480591,
      "eval_rewards/chosen": 0.09031633287668228,
      "eval_rewards/margins": 0.15620920062065125,
      "eval_rewards/rejected": -0.06589288264513016,
      "eval_runtime": 294.0678,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.136,
      "step": 5400
    },
    {
      "epoch": 2.6545981173063,
      "grad_norm": 15.703372955322266,
      "learning_rate": 1.1475937550297763e-07,
      "logits/chosen": -2.0397145748138428,
      "logits/rejected": -1.9955500364303589,
      "logps/chosen": -382.0073547363281,
      "logps/rejected": -334.6173400878906,
      "loss": 0.6352,
      "rewards/accuracies": 0.6416666507720947,
      "rewards/chosen": 0.08322518318891525,
      "rewards/margins": 0.17324310541152954,
      "rewards/rejected": -0.09001794457435608,
      "step": 5500
    },
    {
      "epoch": 2.6545981173063,
      "eval_logits/chosen": -2.001628875732422,
      "eval_logits/rejected": -2.0314338207244873,
      "eval_logps/chosen": -392.9978942871094,
      "eval_logps/rejected": -350.1672668457031,
      "eval_loss": 0.6419406533241272,
      "eval_rewards/accuracies": 0.6387225389480591,
      "eval_rewards/chosen": 0.09238182753324509,
      "eval_rewards/margins": 0.1565294861793518,
      "eval_rewards/rejected": -0.06414764374494553,
      "eval_runtime": 294.4784,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 5500
    },
    {
      "epoch": 2.7028723147477676,
      "grad_norm": 18.993549346923828,
      "learning_rate": 9.866409142121358e-08,
      "logits/chosen": -2.020974636077881,
      "logits/rejected": -2.0068116188049316,
      "logps/chosen": -357.5652770996094,
      "logps/rejected": -342.70452880859375,
      "loss": 0.6373,
      "rewards/accuracies": 0.6449999809265137,
      "rewards/chosen": 0.10266740620136261,
      "rewards/margins": 0.1649647206068039,
      "rewards/rejected": -0.06229730695486069,
      "step": 5600
    },
    {
      "epoch": 2.7028723147477676,
      "eval_logits/chosen": -2.0018558502197266,
      "eval_logits/rejected": -2.031660318374634,
      "eval_logps/chosen": -393.00823974609375,
      "eval_logps/rejected": -350.1818542480469,
      "eval_loss": 0.6418643593788147,
      "eval_rewards/accuracies": 0.6387225389480591,
      "eval_rewards/chosen": 0.09135162085294724,
      "eval_rewards/margins": 0.15695872902870178,
      "eval_rewards/rejected": -0.06560710817575455,
      "eval_runtime": 294.6207,
      "eval_samples_per_second": 3.394,
      "eval_steps_per_second": 1.134,
      "step": 5600
    },
    {
      "epoch": 2.751146512189235,
      "grad_norm": 17.671260833740234,
      "learning_rate": 8.256880733944954e-08,
      "logits/chosen": -2.0411646366119385,
      "logits/rejected": -2.000286340713501,
      "logps/chosen": -386.1936340332031,
      "logps/rejected": -342.91815185546875,
      "loss": 0.6318,
      "rewards/accuracies": 0.6383333206176758,
      "rewards/chosen": 0.10655809193849564,
      "rewards/margins": 0.18091541528701782,
      "rewards/rejected": -0.0743573009967804,
      "step": 5700
    },
    {
      "epoch": 2.751146512189235,
      "eval_logits/chosen": -2.002040386199951,
      "eval_logits/rejected": -2.0318570137023926,
      "eval_logps/chosen": -393.00677490234375,
      "eval_logps/rejected": -350.1839294433594,
      "eval_loss": 0.6417869925498962,
      "eval_rewards/accuracies": 0.6387225389480591,
      "eval_rewards/chosen": 0.09149664640426636,
      "eval_rewards/margins": 0.15731395781040192,
      "eval_rewards/rejected": -0.06581730395555496,
      "eval_runtime": 294.1668,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 5700
    },
    {
      "epoch": 2.799420709630702,
      "grad_norm": 20.515567779541016,
      "learning_rate": 6.64735232576855e-08,
      "logits/chosen": -1.9907996654510498,
      "logits/rejected": -1.9819247722625732,
      "logps/chosen": -385.8754577636719,
      "logps/rejected": -339.4146728515625,
      "loss": 0.6252,
      "rewards/accuracies": 0.6733333468437195,
      "rewards/chosen": 0.09141441434621811,
      "rewards/margins": 0.19784383475780487,
      "rewards/rejected": -0.10642942786216736,
      "step": 5800
    },
    {
      "epoch": 2.799420709630702,
      "eval_logits/chosen": -2.002134323120117,
      "eval_logits/rejected": -2.03193736076355,
      "eval_logps/chosen": -393.0193176269531,
      "eval_logps/rejected": -350.2013854980469,
      "eval_loss": 0.6417312026023865,
      "eval_rewards/accuracies": 0.6397204995155334,
      "eval_rewards/chosen": 0.09024383872747421,
      "eval_rewards/margins": 0.15780261158943176,
      "eval_rewards/rejected": -0.06755877286195755,
      "eval_runtime": 294.8951,
      "eval_samples_per_second": 3.391,
      "eval_steps_per_second": 1.133,
      "step": 5800
    },
    {
      "epoch": 2.84769490707217,
      "grad_norm": 23.84370231628418,
      "learning_rate": 5.0378239175921454e-08,
      "logits/chosen": -1.9734845161437988,
      "logits/rejected": -2.0028836727142334,
      "logps/chosen": -385.5265197753906,
      "logps/rejected": -340.59686279296875,
      "loss": 0.6427,
      "rewards/accuracies": 0.6466666460037231,
      "rewards/chosen": 0.08747594058513641,
      "rewards/margins": 0.15751811861991882,
      "rewards/rejected": -0.07004217803478241,
      "step": 5900
    },
    {
      "epoch": 2.84769490707217,
      "eval_logits/chosen": -2.0018465518951416,
      "eval_logits/rejected": -2.0316195487976074,
      "eval_logps/chosen": -393.0242004394531,
      "eval_logps/rejected": -350.2091369628906,
      "eval_loss": 0.6416937708854675,
      "eval_rewards/accuracies": 0.6397204995155334,
      "eval_rewards/chosen": 0.08975685387849808,
      "eval_rewards/margins": 0.15809433162212372,
      "eval_rewards/rejected": -0.06833747029304504,
      "eval_runtime": 294.3934,
      "eval_samples_per_second": 3.397,
      "eval_steps_per_second": 1.135,
      "step": 5900
    },
    {
      "epoch": 2.8959691045136373,
      "grad_norm": 18.92440414428711,
      "learning_rate": 3.428295509415741e-08,
      "logits/chosen": -2.110055446624756,
      "logits/rejected": -2.059171199798584,
      "logps/chosen": -379.4071350097656,
      "logps/rejected": -333.1321105957031,
      "loss": 0.6306,
      "rewards/accuracies": 0.6549999713897705,
      "rewards/chosen": 0.06651291251182556,
      "rewards/margins": 0.18358412384986877,
      "rewards/rejected": -0.11707121133804321,
      "step": 6000
    },
    {
      "epoch": 2.8959691045136373,
      "eval_logits/chosen": -2.002035617828369,
      "eval_logits/rejected": -2.031822919845581,
      "eval_logps/chosen": -393.0234375,
      "eval_logps/rejected": -350.2098693847656,
      "eval_loss": 0.6416618227958679,
      "eval_rewards/accuracies": 0.6397204995155334,
      "eval_rewards/chosen": 0.08982784301042557,
      "eval_rewards/margins": 0.15823674201965332,
      "eval_rewards/rejected": -0.06840889900922775,
      "eval_runtime": 294.2246,
      "eval_samples_per_second": 3.399,
      "eval_steps_per_second": 1.135,
      "step": 6000
    },
    {
      "epoch": 2.944243301955105,
      "grad_norm": 24.23944091796875,
      "learning_rate": 1.818767101239337e-08,
      "logits/chosen": -2.0382795333862305,
      "logits/rejected": -2.0031626224517822,
      "logps/chosen": -393.5494384765625,
      "logps/rejected": -350.7118835449219,
      "loss": 0.6445,
      "rewards/accuracies": 0.643333375453949,
      "rewards/chosen": 0.08841471374034882,
      "rewards/margins": 0.14624455571174622,
      "rewards/rejected": -0.057829827070236206,
      "step": 6100
    },
    {
      "epoch": 2.944243301955105,
      "eval_logits/chosen": -2.0020432472229004,
      "eval_logits/rejected": -2.0318281650543213,
      "eval_logps/chosen": -393.02490234375,
      "eval_logps/rejected": -350.2124328613281,
      "eval_loss": 0.6416412591934204,
      "eval_rewards/accuracies": 0.6397204995155334,
      "eval_rewards/chosen": 0.08968362212181091,
      "eval_rewards/margins": 0.15835046768188477,
      "eval_rewards/rejected": -0.06866684556007385,
      "eval_runtime": 294.4309,
      "eval_samples_per_second": 3.396,
      "eval_steps_per_second": 1.134,
      "step": 6100
    },
    {
      "epoch": 2.9925174993965724,
      "grad_norm": 17.23649787902832,
      "learning_rate": 2.0923869306293254e-09,
      "logits/chosen": NaN,
      "logits/rejected": -2.038714647293091,
      "logps/chosen": -377.1180725097656,
      "logps/rejected": -336.2071533203125,
      "loss": 0.6331,
      "rewards/accuracies": 0.6516667008399963,
      "rewards/chosen": 0.09301068633794785,
      "rewards/margins": 0.17386482656002045,
      "rewards/rejected": -0.080854132771492,
      "step": 6200
    },
    {
      "epoch": 2.9925174993965724,
      "eval_logits/chosen": -2.0020408630371094,
      "eval_logits/rejected": -2.0318243503570557,
      "eval_logps/chosen": -393.0242004394531,
      "eval_logps/rejected": -350.2122497558594,
      "eval_loss": 0.6416323781013489,
      "eval_rewards/accuracies": 0.6397204995155334,
      "eval_rewards/chosen": 0.08975405991077423,
      "eval_rewards/margins": 0.1583985984325409,
      "eval_rewards/rejected": -0.06864452362060547,
      "eval_runtime": 294.8402,
      "eval_samples_per_second": 3.392,
      "eval_steps_per_second": 1.133,
      "step": 6200
    }
  ],
  "logging_steps": 100,
  "max_steps": 6213,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
